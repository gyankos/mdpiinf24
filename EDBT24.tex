%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}
\usepackage{braket,booktabs,subcaption,xfrac,multirow}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{rightsretained}
\copyrightyear{2024}
\acmYear{2024}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[EDBT'24]{27th International Conference on Extending Database Technology}{March 25--28,
  2023}{P\ae\null stum, IT}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
\usepackage{amsmath,cleveref}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{booktabs}

\makeatletter
\DeclareRobustCommand{\iscircle}{\mathord{\mathpalette\is@circle\relax}}
\newcommand\is@circle[2]{%
  \begingroup
  \sbox\z@{\raisebox{\depth}{$\m@th#1\bigcirc$}}%
  \sbox\tw@{$#1\square$}%
  \resizebox{!}{\ht\tw@}{\usebox{\z@}}%
  \endgroup
}
\makeatother

\newcommand{\llbraket}{\ensuremath{[\![}}
\newcommand{\rrbraket}{\ensuremath{]\!]}}
\newcommand{\gsep}{\ensuremath{\;|\;}}
\newcommand{\Next}{\ensuremath{\iscircle}}
\newcommand{\Globally}{\ensuremath{\square}}
\newcommand{\Future}{\ensuremath{\Diamond}}
%\newcommand{\Until}[2]{#1\;\mathcal{U}\;#2}
\newcommand{\WeakUntil}[2]{\ensuremath{{#1}\;\mathcal{W}\;{#2}}}
\newcommand{\DUntil}[2]{\ensuremath{{#1}\;\mathcal{U}\;{#2}}}
\newcommand{\MonoDeclareClause}[4]{\textsf{#1}(\texttt{#2},#3,{#4})}
\newcommand{\DeclareClause}[5]{\textsf{#1}(\texttt{#2},\texttt{#4})}
\newcommand{\DeclareClauseWithJoin}[6]{\textsf{#1}(\texttt{#2},#3,\texttt{#4},#5)\;\textsf{where}\;#6}
\newcommand{\DeclareClauseNoData}[3]{\textsf{#1}(\texttt{#2},\texttt{#3})}
\usepackage{xspace}
\newcommand{\const}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\Sdeclare}[3]{\DeclareClause{#1}{#2}{\textbf{true}}{#3}{\textbf{true}}}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage[noend]{algpseudocode}
%% Multiline
\newcommand\CONDITION[2]%
{\begin{tabular}[t]{@{}l@{}l@{}}
		#1&#2
	\end{tabular}%
}
\algdef{SE}[WHILE]{While}{EndWhile}[1]%
{\algorithmicwhile\ \CONDITION{#1}{\ \algorithmicdo}}%
{\algorithmicend\ \algorithmicwhile}
\algdef{SE}[FOR]{For}{EndFor}[1]%
{\algorithmicfor\ \CONDITION{#1}{\ \algorithmicdo}}%
{\algorithmicend\ \algorithmicfor}
\algdef{S}[FOR]{ForAll}[1]%
{\algorithmicforall\ \CONDITION{#1}{\ \algorithmicdo}}
\algdef{SE}[REPEAT]{Repeat}{Until}{\algorithmicrepeat}[1]%
{\algorithmicuntil\ \CONDITION{#1}{}}
\algdef{SE}[IF]{If}{EndIf}[1]%
{\algorithmicif\ \CONDITION{#1}{\ \algorithmicthen}}%
{\algorithmicend\ \algorithmicif}%
\algdef{C}[IF]{IF}{ElsIf}[1]%
{\algorithmicelse\ \algorithmicif\ \CONDITION{#1}{\ \algorithmicthen}}
%% End Multiline
\usepackage{algorithm,algorithmicx}
\algnewcommand{\IIf}[1]{\State\algorithmicif\ #1\ \algorithmicthen}
\algnewcommand{\EndIIf}{\unskip\ \algorithmicend\ \algorithmicif}
%\makeatletter
%\algrenewcommand\ALG@beginalgorithmic{\ttfamily}
%\makeatother
\usepackage{adjustbox} %% Fitting to pageRichard
\definecolor{oceanboatblue}{rgb}{0.0, 0.47, 0.75}
\newcommand{\eqdef}{\overset{\mathrm{def}}{=\joinrel=}}
%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title[Streamlining Temporal Formal Verification over Columnar Databases]{Streamlining Temporal Formal Verification\\ over Columnar Databases}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Giacomo Bergami}
\orcid{0000-0002-1844-0851}
\email{Giacomo.Bergami@newcastle.ac.uk}
\affiliation{%
	\institution{Newcastle University\\ School of Computing}
	\country{United Kingdom}
}
%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
%This paper proposes four novel relational operators over columnar databases for 
%streamlining the execution of temporal formal verification tasks. {\color{red}[Better detail
%the difference between the previous implementation]} Our experiments show that {\color{red}[Details]}
Recent findings demonstrate how database technology enhances the computation of formal verification tasks expressed in linear time logic for finite traces. Human readable declarative languages also help the common practitioner to express temporal constraints in a straightforward and accessible language. Notwithstanding the former, this technology is in its infancy, and therefore, few optimization algorithms are known for dealing with massive amounts of information audited from real systems. We, therefore, advocate for novel algorithms over relational representation for logs and traces, outperforming previous state-of-the-art implementations, thus leading to the formulation of unknown derived temporal operators.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10003790.10011192</concept_id>
       <concept_desc>Theory of computation~Verification by model checking</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003790.10003793</concept_id>
       <concept_desc>Theory of computation~Modal and temporal logics</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809</concept_id>
       <concept_desc>Theory of computation~Design and analysis of algorithms</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10002951.10002952.10003190.10010840</concept_id>
       <concept_desc>Information systems~Main memory engines</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[300]{Theory of computation~Verification by model checking}
\ccsdesc[500]{Theory of computation~Modal and temporal logics}
\ccsdesc[500]{Theory of computation~Design and analysis of algorithms}
\ccsdesc[500]{Information systems~Main memory engines}
\newcommand{\spec}{\ensuremath{\Phi}}
\newcommand{\LOG}{\ensuremath{\mathfrak{S}}}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Temporal Formal Verification, Columnar Databases, Verified Artificial Intelligence, Linear Time Logic for Finite Traces}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
%\begin{teaserfigure}
%  \includegraphics[width=\textwidth]{sampleteaser}
%  \caption{Seattle Mariners at Spring Training, 2010.}
%  \Description{Enjoying the baseball game from the third-base
%  seats. Ichiro Suzuki preparing to bat.}
%  \label{fig:teaser}
%\end{teaserfigure}

\received{3 October 2023}
\received[revised]{XX YY ZZZZ}
\received[accepted]{XX YY ZZZZ}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Grounded on formal methods, verified artificial intelligence \cite{DBLP:journals/cacm/SeshiaSS22} is concerned with defining, designing, and verifying mathematically represented systems. In context-free data, this focuses on a system $\LOG$ to be verified through a property described in $\spec$, while the model of the environment $\mathfrak{E}$ is neglected. In this regard, a \textit{formal verification} task ascertains whether a given system complies to a specification $\LOG\vDash \spec$. 
In the context of business process management, we can consider \textit{model} \cite{DBLP:books/daglib/0020348}, \textit{conformance} \cite{DBLP:conf/bpm/BergamiMMM21}, or \textit{compliance} \cite{DBLP:conf/bpm/AwadDW08,WEIDLICH20111009} \textit{checking} as all synonyms of the former. Concerning temporal data, we focus our attention on systems described as logs, a collection of temporally ordered records (i.e., \textit{traces}) of observed and completed (or aborted) labelled activities unravelling one possible run of a process. These real-world processes might include the auditing of malware in terms of system calls being invoked \cite{10.7717/peerj-cs.346,DBLP:conf/siu/YaziCG19}, records describing patients' hospitalisation procedures  \cite{8782520,XuPYYLZ20,https://doi.org/10.4121/uuid:d9769f3d-0ab0-4fb8-803b-0d1120ffcf54}, as well as transactions between producers and retailers through a brokerage system \cite{DBLP:conf/wbdb/PetermannJMR14}. In all these contexts, a formal verification task returns whether the current instances of the processes being collected as traces of a log abide by specific quality requirements while determining which temporal constraints are explicitly violated. In these contexts, Linear Temporal Logic over Finite traces (LTL\textsubscript{f}, \S\ref{ssec:languages}) \cite{DBLP:conf/ijcai/GiacomoV13} can be used to express these temporal specifications $\spec$ in their entirety. This logic is defined as linear since it assumes there is only one future possible event immediately following a given event in a sequence of events of interest. Such low-level semantics are then exploited to give the semantics of temporal templates, expressing occurring temporal correlations of interest; the present paper will discuss Declare \cite{4384001}. 

\begin{table*}[!th]
	\centering
	\caption{Declare \textsf{templates} as exemplifying clauses. $A$ ($B$) represents the \textit{activation} (\textit{target}) condition as an  activity label.}\label{tab:dt}
	\resizebox{\textwidth}{!}{\begin{tabular}{c|l|p{9cm}|l}
			\toprule
			 & Exemplifying clause ($c_l$) & Natural Language Specification for Traces & LTL\textsubscript{f} Semantics ($\llbracket c_l \rrbracket$)\\
			\midrule
				 & \textsf{ChainPrecedence($A,B$) }  & The activation is immediately preceded by the target. & $\Globally(\Next A\Rightarrow B)$\\ 


			\parbox[t]{2mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{\textit{In this paper}}}} & \textsf{ChainResponse($A,B$) }  & The activation is immediately followed by the target. & $\Globally(A\Rightarrow \Next B )$\\
			
			& \textsf{AltResponse($A,B$) }  & If activation occurs, no other activations must happen until the target occurs.  & $\Globally(A\Rightarrow\Next(\DUntil{\neg A}{B}))$\\
			& \textsf{AltPrecedence($A,B$) }  & Every activation must be preceded by a target without any other
			activation in between &   $\WeakUntil{\neg B}{A}\wedge \Globally(A\Rightarrow \Next(\WeakUntil{\neg A}{B }))$\\
\midrule
	  \parbox[t]{2mm}{\multirow{2}{*}{\rotatebox[origin=c]{90}{\textit{Not subject to optimization in this paper}}}}  & \textsf{Init($A$)} & The trace should start with an activation & $A$\\
	 & \textsf{Exists($A,n$)} & Activations should occur at least $n$ times & $\Future(A\wedge \Next (\llbracket\textsf{Exists} (A,n-1)\rrbracket))$\\
	 & \textsf{Absence($A,n+1$)}  & Activations should occur at most $n$ times & $\neg \llbracket\textsf{Exists}$($A,n+1$)$\rrbracket$\\
	 & \textsf{Precedence($A,B$)}  & Events preceding the activations should not satisfy the target & $\WeakUntil{\neg B}{A}$\\
	& \textsf{Choice($A,A'$) }  & One of the two activation  conditions must appear. & $\Future A\vee\Future A'$ \\
	 & \textsf{Response($A,B$) } & The activation is either followed by or simultaneous to  the target. & $\Globally(A\Rightarrow\Future B)$ \\
	 & \textsf{RespExistence($A,B$) }  & The activation requires the existence of the target.& $\Future A\Rightarrow\Future B$ \\
	 & \textsf{ExlChoice($A,A'$) } & Only one activation condition must happen. & $\llbracket\DeclareClause{Choice}{A}{p}{A'}{p'}\rrbracket\wedge \llbracket\DeclareClause{NotCoExistence}{A}{p}{A'}{p'}\rrbracket$\\ 
	 & \textsf{CoExistence($A,B$) }  & \textsf{RespExistence}, and vice versa. & $ \llbracket\DeclareClauseNoData{RespExistence}{A}{B}\rrbracket\wedge \llbracket\DeclareClauseNoData{RespExistence}{B}{A}\rrbracket$\\
	 & \textsf{Succession($A,B$) }  & The target should only follow the activation. & $\llbracket\DeclareClauseNoData{Precedence}{A}{B}\rrbracket\wedge \llbracket\DeclareClauseNoData{Response}{A}{B}\rrbracket$\\

	 & \textsf{ChainSuccession($A,B$) }  & Activation immediately follows the target, and the target immediately preceeds the activation. & $\Globally(A\Leftrightarrow\Next B)$\\

	 
	& \textsf{NotCoExistence($A,B$) } & The activation \texttt{nand} the target happen.&  $\neg(\Future A \wedge\Future B)$\\
	 & \textsf{NotSuccession($A,B$)} & The activation requires that no target condition should follow.& $\Globally(A\Rightarrow \neg\Future B)$ \\
			\bottomrule
	\end{tabular}}
\end{table*}
The emerging area of temporal big data analytics, having data with time as a first-class citizen, makes the need to efficiently processing the aforementioned tasks more pressing \cite{cuzzocrea:LIPIcs.TIME.2021.4,DBLP:reference/db/Amer-YahiaPTKDC18}. In such real scenarios, adopting relational databases provides an ideal setting for dealing with such temporal data \cite{DBLP:conf/caise/SchonigRCJM16}. This also includes the storage and querying of numerical
time series \cite{DBLP:journals/pacmmod/HuangZCS23}, or considering different versions in time of entities and relationships represented in the relational
model \cite{5963680,DBLP:journals/pvldb/KaufmannVFKF13,DBLP:journals/isci/WangJS95,DBLP:conf/cikm/Wang95}. In recent years, researchers have demonstrated that time series can be represented as traces via time series segmentation by discretizing the variation in time series into discrete, observable, linear events that are distinct from each other, enabling identification of a system's transitional states \cite{DBLP:journals/pacmmod/00080ZC23} as well as variations in the values associated with time series \cite{HUO2022117176}. As a result of such segmentation, pattern searches can now be run using streamlined approaches. LTL\textsubscript{f} has now been applied to a widespread set of applications in real use case scenario contexts, such as controlling actuation upon sensing the environment in Industry 4.0 settings  \cite{9591387} as well as for the verification of smart contracts \cite{10.1007/978-3-031-08421-8_9}, for which this technology proved to be effective for verified artificial intelligence. The large adoption of such formal language  pushes us to focus on this well-known and consolidated language \cite{4567924,DBLP:conf/ijcai/GiacomoV13}.

In the context of formal specification tasks expressed in LTL\textsubscript{f}, recent research clearly remarked the inadequacy of off-the-shelf row-based relational databases and SQL as a query language for expressing LTL\textsubscript{f} temporal constraints, as it clearly showed that a customised relational algebra for expressing formal specification (\texttt{xt}LTL\textsubscript{f} \cite{info14030173}) and query plan minimising the running of sub-queries \cite{BellatrecheKB21} running on customised column-based storage outperformed the previous solution. The main benefit of this approach is that any LTL\textsubscript{f} can be directly expressed in terms of \texttt{xt}LTL\textsubscript{f}, while high-level and human-readable temporal constraints expressed through temporal clauses can be directly specified in a semantics file to be loaded at warm-up, thus allowing the support of any declarative temporal language. As this line of research is in its infancy, very few algorithms for efficiently running \texttt{xt}LTL\textsubscript{f} are known. We now remark on two noteworthy examples.

\textit{First}, due to their formulation, some of the logical operators such as the timed until operator \textsc{Until}$^\tau_\textbf{True}(\varphi,\varphi')$ ($\varphi \mathcal{U}\varphi'$ in LTL\textsf{f}) are associated with very high computational complexity, as it prescribes that the occurrence of at least one future event matching a $\varphi'$ condition per trace shall always be preceded by events matching $\varphi$. Under the occasions that this temporal post-condition shall be considered only after determining the occurrence of a first event  $\varphi''$, this could drastically reduce the amount of computation associated with the overall task. This is not taken into account in the current implementation, as our previous solution computed a union between the cases where $\varphi''$ does not occur and the ones where $\varphi''$ occurs, for which the evaluation of \textsc{Until}$^\tau_\textbf{True}(\varphi,\varphi')$ is extended to any event occurring of the trace. Walking on the footsteps of relational algebra, where $\theta$-joins are expressed as the combination of natural joins \cite{DBLP:books/mg/AtzeniCPT99} or cross-products \cite{10.5555/2842853} with $\theta$-selections and join operations can be streamlined through cogrouping \cite{DBLP:books/x/dittrich2016}, we then propose similarly derived operators, combining the matching of a given pre-condition with the subsequent requirement that all the intermediate events should meet the alternance requirements dictated by \textsc{Until}$^\tau_\Theta$. This paper will then contextualise the need for such derived operators for two specific Declare temporal specifications, \texttt{AltPrecedence} and \texttt{AltResponse}, thus substantiating the interest in these temporal patterns from current literature.

\textit{Second}, temporal constraints requiring that events abiding by a $\varphi$ specification shall always precede (or follow) other events abiding by $\varphi'$, are currently implemented in KnoBAB by equi-joining all the events matching  $\varphi$ with the ones matching $\varphi'$, while the predicate is $i=i' \wedge j=j-1$ (or $i=i' \wedge j=j'+1$), where $i$ (or $i'$) and $j$ (or $j'$) are respectively referring to the trace id and event id associated to a record coming from the first (or second) operand. Even this implementation can be further boosted by minimising the data table access to just one operator (e.g., $\varphi$) for directly accessing the immediately preceding or following events within the relational database and checking whether they abide by $\varphi'$. Even this second observation is motivated by the existence of \texttt{ChainResponse} and \texttt{ChainPrecedence} Declare templates, thus requiring the definition of novel derived operators for performance purposes.




%outperformed the previous implementation. 



To support our research claims, we extend\footnote{\url{https://github.com/datagram-db/knobab/releases/tag/v2.3}} the current implementation of KnoBAB \cite{computers12090185}, a column-oriented main memory DBMS supporting formal verification and specification mining tasks by defining relational operations for temporal logic and customary mining algorithms. Despite this being a main memory engine, it currently supports intra-query parallelism and hybrid algorithms. To our knowledge, no other database management system for temporal formal verification over LTL\textsubscript{f} provides these features, for which we choose to extend such a system. Furthermore, KnoBAB already proved to consistently outperform previous state-of-the-art algorithms on both tasks, thus including competing approaches interpreting the same temporal constraints over SQL and row-oriented relational database architecture \cite{DBLP:conf/caise/SchonigRCJM16}. After providing a brief literature overview on the landscape of formal verification for temporal data (\S\ref{sec:relwork}), we outline the following main contributions:
\begin{itemize}
\item We formally introduce the novel temporal operators optimising the aforementioned scenarios in the context of Declare as a declarative language for formal verification (\S\ref{sec:opdef}).
\item We describe the implementation of the aforementioned operators over the KnoBAB architecture leveraging columnar-oriented main memory storage (\S\ref{sec:algos}).
\item We present experimental results to evaluate the effectiveness of such newly introduced operators in the context of formal verification in Declare (\S\ref{sec:empeval}). 
\end{itemize}


\section{Related Works}\label{sec:relwork}
\subsection{Languages for Temporal Formal Specifications}\label{ssec:languages}
\subsubsection{LTL\textsubscript{f}}
Taking the possible worlds as finite traces, LTL\textsubscript{f} is a well-established extension of modal logic, assuming that all the events of interest are fully observable and therefore deterministic and that, for each occurring event, they should be immediately followed by at most one event. This entails that the $i$-th trace $\sigma^i$ in a log $\LOG$ can be considered as a sequence of $n$ totally ordered events $\sigma^i_0\dots\sigma^i_{n-1}$, where each event $\sigma^i_j$ is associated to a single activity label $\lambda(\sigma^i_j)\in\Sigma$ \cite{DBLP:conf/bpm/BergamiMMM21}.  LTL\textsubscript{f} semantics it is usually defined in terms of First Order Logic \cite{DBLP:conf/tamc/ZhuPV19}; more informally, \texttt{Next} ($\Next\phi$) requires $\phi$ to occur from the subsequent temporal step, \texttt{Globally} ($\Globally\phi$) that $\phi$  always holds from the current instant of time, \texttt{Future} ($\Future\phi$)  that $\phi$ must eventually hold, and  \texttt{Until} $\DUntil{\phi}{\phi'}$ that $\phi$ must hold until the first occurrence of $\phi'$ does. \textbf{W}eak Until is a \textit{derived operator} for ${\varphi}\mathcal{W}{\varphi'}:={\varphi}\mathcal{U}{\varphi'}\vee\Globally{\varphi}$, while the logical implication can be rewritten as $\varphi\Rightarrow\varphi':=(\neg \varphi)\vee (\varphi\wedge \varphi')$.

\begin{table}
\caption{Traces distinguishing the temporal behaviour of the Declare clauses of interest in this paper, where each trace $\sigma^i_0\dots\sigma^i_{n-1}$ is expressed in terms of their associated activity labels, $\braket{\lambda(\sigma^i_0),\dots, \lambda(\sigma^i_{n-1})}$.}\label{btable}
\centering
	\begingroup % trick algorithm2e into thinking we're in one column mode
	\csname @twocolumnfalse\endcsname
	\noindent
	\resizebox{\textwidth}{!}{%
		\begin{minipage}{1.6\textwidth}\begin{tabular}{lcccc}
\toprule
     Traces & \texttt{ChainResponse}(\textsf{A,B}) &\texttt{ChainPrecedence}(\textsf{A,B}) & \texttt{AltResponse}(\textsf{A,B}) & \texttt{AltPrecedence}(\textsf{B,A})\\
\midrule
    $\braket{\textsf{A,B,C,B}}$ & \cmark & \xmark & \cmark& \xmark \\
    $\braket{\textsf{A,B,A}}$& \xmark & \cmark & \xmark& \xmark \\
    $\braket{\textsf{A,D,B}}$ & \xmark & \xmark & \cmark& \xmark\\
    $\braket{\textsf{C,B,A}}$ & \xmark & \xmark & \xmark & \cmark \\
\bottomrule
\end{tabular}		\end{minipage}%
	}% <------------- end of \resizebox
\endgroup
\end{table}
\subsubsection{Declare.} Declare \cite{4384001,Li2020} provides a human-readable declarative language on top of LTL\textsubscript{f} (first column  of Table \ref{tab:dt}), where each template is associated with a specific LTL\textsf{f} formula (third column), which can be instantiated with arbitrary activity labels. We refer to the instantiation of such templates via activity labels in a finite set $\Sigma$ as \textit{(declarative) clauses}. Declare circumscribes the set of all the possible behaviours expressible in LTL\textsubscript{f} to the ones of interest over a set of possible  $\Sigma$: Table \ref{tab:dt} recalls some of the most used templates while remarking the four one of interest optimised in the present paper. At the time of the writing, Declare expresses specifications $\spec$ as a set of clauses $c_l$ being associated to an LTL\textsubscript{f} semantics $\llbracket c_l\rrbraket$; in this context, a trace $\sigma\in\LOG$ satisfies a Declare specification $\spec$ if it jointly satisfies all the clauses associated to the specification. If these clauses can be characterized by a precondition which, if satisfied by some event, imposes the occurrence of a post-condition, then we refer to these as \textit{activation} and \textit{target} conditions respectively. Please consider that Declare clauses do not necessarily reflect association rules, as the latter do not provide temporal constraints correlating the activation of activation and target conditions. In this paper, we focus on Declare clauses only predicating over the events' activity labels, which are then referred to as \textit{dataless}; considering our datasets of interest, we are going to consider similar dataset where trace events are not associated with a data payload, and therefore even such logs can be considered as \textit{dataless}. Both clauses and logs are referred to \textit{dataful} otherwise. 

Despite the four clauses of interest in \tablename~\ref{tab:dt} might appear to express similar behaviour, they express substantially different concepts: \tablename~\ref{btable} provides four traces distinguishing the behaviour of such four templates, which validity can be easily controlled by transforming the associated LTL\textsubscript{f} formul\ae~ into a DFA\footnote{\url{http://ltlf2dfa.diag.uniroma1.it/dfa}}.

\begin{table}
\caption{KnoBAB representation for the dataless log in Eq. \ref{ourLog}.}\label{atable}

\begin{subtable}[c]{\linewidth}\centering
\caption{ActivityTable}\label{acttable}
\begin{tabular}{lllcc}
\toprule
     \texttt{ActivityLabel} & \texttt{TraceId} & \texttt{EventId} &  \texttt{Prev} & \texttt{Next}\\
\midrule
    \textit{Clinical Test} & 1 &  2 & 7 & 5\\
    \textit{Discharge} & 0 & 2 & 4 & NULL\\
    \textit{Discharge} & 1 &  4 & 5& NULL\\
    \textit{Discharge} & 2 &  3  & 6& NULL\\
    \textit{Examination} & 0 & 1 & 9 & 1\\
    \textit{Examination} & 1 &  3 & 0& 2\\
    \textit{Examination} & 2 &  2 &8&3\\
    \textit{Redirection} & 1 & 1 & 10 & 0 \\
    \textit{Redirection} & 2 & 1 & 11 & 6\\
    \textit{Registration} & 0 & 0 & \texttt{NULL} & 4\\
    \textit{Registration} & 1 &  0 & \texttt{NULL} & 7\\
    \textit{Registration} & 2 &  0 & \texttt{NULL} &  8\\
\bottomrule
\end{tabular}
\end{subtable}

\begin{subtable}[c]{\linewidth}\centering
\caption{CountTable}\label{counttable}
\begin{tabular}{lll}
\toprule
     \texttt{ActivityLabel} & \texttt{TraceId} & \texttt{Count} \\
\midrule
    \textit{Clinical Test} & 0 &  0\\
    \textit{Clinical Test} & 1 &  1\\
    \textit{Clinical Test} & 1 &  0\\
    \textit{Discharge} & 0 & 1\\
    \textit{Discharge} & 1 & 1\\
    \textit{Discharge} & 2 & 1\\
    \textit{Examination} & 0 & 1\\
    \textit{Examination} & 1 &  1\\
    \textit{Examination} & 2 &  1\\
    \textit{Redirection} & 0 & 0\\
    \textit{Redirection} & 1 & 1\\
    \textit{Redirection} & 2 & 1\\
    \textit{Registration} & 0 & 1\\
    \textit{Registration} & 1 &  1\\
    \textit{Registration} & 2 & 1\\
\bottomrule
\end{tabular}
\end{subtable}

\end{table}
\subsection{KnoBAB and \texttt{xt}LTL\textsubscript{f}}
\textit{We now summarise our previous contributions on temporal formal verification tasks run over our proposed main memory columnar database, KnoBAB.}
\subsubsection{KnoBAB}
\textit{KnoBAB} \cite{info14030173,computers12090185} is a column-database store tailored for both loading \textit{dataful} logs being represented in XES \cite{DBLP:journals/cim/AcamporaVSAGV17} and \textit{dataless} ones described as a tab-separated file. This outperformed the previous state of the art in terms of both specification mining \cite{APrioriDeclare} and formal verification \cite{BurattinMS16} tasks on tailored non-database solutions.  

\paragraph{Logical and Physical Model.} The resulting column-based relational database is then represented through some tables having fixed schema independently from its data representation. As the present paper focuses on dataless datasets, we describe in this paper just two of those: \tablename~\ref{atable} describes the relational representation of three distinct patient registration events at an emergency department (ED) \cite{Petsis2022} as given by the following log expressed in terms of the activity labels associated to our events:
\begin{equation}\label{ourLog}
\begin{split}
\LOG=\{&\braket{\texttt{registration},\texttt{examination},\texttt{discharge}},\\
      &\langle\texttt{registration},\texttt{redirection},\texttt{clinical test},\\
      &\;\texttt{examination}, \texttt{discharge}  \rangle,\\
      &\langle\texttt{registration},\texttt{redirection},\texttt{examination},\\
      &\; \texttt{discharge}  \rangle\}\\
\end{split}
\end{equation}
The ActivityTable (\tablename~\ref{acttable}) lists each trace event of a given log, where records are sorted in ascending order for activity label, trace id, and event id. Cells under the  \texttt{Prev} (and \texttt{Next}) column store a pointer to the record representing the immediately preceding (and following) event in the same trace if any. After mapping each existing activity label in the log $\const{a}$ to a unique natural number $\beta(\const{a})$, we can define a primary dense and clustered index  that can be accessed in $O(1)$ time as it is an array of offset pointers. We also define a secondary index structured as a block of two records, associating each trace in the log to the  first and last trace event; given that all the traces are associated with a unique natural number, this index can also be accessed on $O(1)$ time by trace id. The CountTable (\tablename~\ref{counttable}), also created at loading time as the previous, merely lists the number of occurrences of each activity label per trace and can be used to determine the absence or presence of an event with a given activity label per trace.

\paragraph{Formal Verification tasks as Query Plans.} In spite of the ActivityTable also appearing in SQLMiner's log representation \cite{SchonigRCJM16} (except for the \texttt{Prev} and \texttt{Next} columns), this still used an off-the-shelf relational database engine and a translation of Declare specification into SQL for carrying out formal verification tasks over a dataless log. KnoBAB showed a new pathway for enhancing temporal queries over customary main memory relational database through the combined provision of both \textit{ad hoc}  relational operators expressing LTL\textsubscript{f} over relational tables (\texttt{xt}LTL\textsubscript{f}) and the definition of a query plan represented as a rooted DAG where shared subqueries are computed only once \cite{BellatrecheKB21}. This was sensibly different from competing approaches \cite{DBLP:books/sp/22/MurillasRA22,DBLP:books/sp/22/KammererPR22} also relying on main memory engines where, instead, the query plan associated to a formal verification task is always expressed in terms of trees, thus not allowing the detection of shared sub-expressions to be merged to avoid wasteful recomputations. As vertices for a DAG can be sorted topologically, we can obtain for three the scheduling order in which the operators must be executed and, by associating each node a maximum distance value from the root, we can safely run in parallel all the operators laying at the same depth level as all the previously-called operators will pertain their information in an intermediate cache, thus achieving intraquery parallelism as a free meal \cite{info14030173}. This parallelization approach greatly differs from straightforward parallelization algorithms known in the Business Process Management area, where they simply run each declarative clause occurring in the specification in a separate thread \cite{BurattinMS16}. In addition to the former, KnoBAB guarantees efficient access to the tables through the provision of specific indexing data structures such as primary indices for directly accessing the blocks of the table concerning a specific activity label as well as the provision of secondary indices mapping a specific trace id $i$ and event id $j$ for $\sigma^i_j$ into a table offset. KnoBAB outperformed SQLMiner run over PostgreSQL within two to five orders of magnitude, thus remarking the inadequacy of using customary relational operators for computing temporal tasks over relational databases. 

%\texttt{\color{red} Other competing approaches also not expressing the query plan as a DAG, but rather as a tree, thus not benefitting from computing the same sub-expressions shared across clauses at most once while also not providing minimal data access to the tables: }

KnoBAB enables the specification of user-defined template names in terms of \texttt{xt}LTL\textsubscript{f} operators through a {\color{oceanboatblue}\texttt{queryplan "semanticsname" \{}...\texttt{\}}} query, thus allowing the co-presence of multiple possible definitions of declarative clauses. Then, we can select the most appropriate semantics while carrying out the formal verification task by specifying such name, e.g. {\color{oceanboatblue}\texttt{model-check} ... \texttt{plan "name"} ...}. This then enables us in this paper to test multiple possible specifications of Declare clauses without necessarily recompiling the database's source code.


Walking in the footsteps of BAT algebra for columnar databases \cite{IdreosGNMMK12}, each of the novel temporal operands for \texttt{xt}LTL\textsubscript{f} (\S\ref{xtltlf}) not requiring accessing the aforementioned KnoBAB tables accept as an input a uniform data representation with schema: \[\footnotesize \texttt{IntermediateRepresentation}(\texttt{TraceId},\texttt{EventId},\texttt{Witnesses(Tag)})\] where the first (and second) argument refers to the trace (and event) id matching a specific temporal condition of choice, while \texttt{witnesses} provide a list of either  activated or targeted conditions occurring from the position \texttt{EventId} in a given \texttt{TraceId} trace onwards, where such distinction is made explicit with appropriate tags, respectively $A$ and $T$. Dataful matching occurring between witnessed activated $A(i)$ and targeted events $T(j)$ certified via a $\Theta$ binary predicate are represented as $M(i,j)$. As the table is sorted by trace id and event id by design for any given activity label, such intermediate representation  also returns  trace entities sorted by ascending trace id and event id.
\bigskip

\subsubsection{\texttt{xt}LTL\textsubscript{f}}\label{xtltlf}
\textit{We now discuss some \texttt{xt}LTL\textsubscript{f} operators of relevance for the current paper. By using KnoBAB as a computational model, we can also discuss the time complexity associated with such operators.} While LTL\textsubscript{f} operators can mainly be used to establish a yes/no question about whether a single trace abides by some temporal specification, an \texttt{xt}LTL\textsubscript{f} expression returns all the traces in the log conforming to a temporal specification by composing the trace events as records through temporal operations. Furthermore, the latter can also be directly exploited to express confidence, maximum satisfiability, and support metrics similar to association rules. 

\paragraph{Table Access (``leaf'') operators.} We  determine all the events being associated with a specific activity label through the ActivityLabel's primary block index and express the outcome of this retrieval in terms of intermediate representation:
\[\footnotesize \textsf{Activity}^{\LOG,\tau}_{A/T}(\const{a})=\{\braket{i,j,\{A/T(j)\}}|\exists \pi,\phi.\braket{\const{a},i,j,\pi,\phi}\in\textsf{ActivityTable}\}\]
whether $A/T$ provides the optional tags for remarking the matching event of interest as being part of an activation/target condition. By associating each activity label \const{a} with a unique natural number $\beta(\const{a})$, we can now seek the presence of events with label \const{a} in $O(1)$ time and retrieve all the events $\#{\textsf{a}}\ll |\LOG|$ associated to such a label. If, on the other hand, we are interested in events matching a specific data predicate $p$,  we define the following operator:
\[\textsf{Atom}^{\LOG,\tau}_{A/T}(\textsf{B},q)=\{\braket{i,j,{A/T(j)}}\;|\;q(\sigma^i_j)\wedge \lambda(\sigma^i_j)=\textsf{B}\}\]
Despite this might appear as a simple selection operation, the atomization of a predicate into mutually exclusive data conditions required for both minimising the data access to the tables holding the key-value payload associations within the dataful events and merging multiple equivalent sub-expressions into one makes both its associated query plan and its formal definition quite convoluted. As describing this is not the major purpose of the paper, we refer to \cite{info14030173}
 for any further information. %Despite this, which might resemble the selection predicate from traditional relational algebra at first glance, the atomization of each key-value correspondence as a distinct table requires additional technical details. Due to the data minimisation access, its formulation is not straightforward. Please observe that its detailed formal specification requires additional knowledge on the representation of the AttributeTables which, due to the lack of space, are not discussed in the present paper but can be found in  \cite{info14030173}. 
By accessing the secondary index of the \textsf{ActivityTable}, we can collect the last events for each trace in linear time over the log's size $O(|\LOG|)$ using the following operator:
\[\tiny\textsf{Last}^{\LOG,\tau}_{A}=\{\braket{i,\vert\sigma^i\vert,\{A(\vert\sigma^i\vert)\}}|\exists \const{a}, \pi.\braket{\beta(\const{a}),i,|\sigma^i|,\pi,\texttt{NULL}}\in\textsf{ActivityTable}\}\]

\paragraph{Unary Operators.} We discuss the main difference between the definition of operators in  \texttt{xt}LTL\textsubscript{f} from corresponding ones in LTL\textsubscript{f}: the former computes semantics from the first occurring operator appearing in the formula towards the leaves, whereas the latter assumes intermediate results from the leaves.  The downstream operator is completely agnostic about the semantics associated with the upstream operator, so it must combine the intermediate results appropriately. Therefore, the \textsf{Next}$(\rho)$ (timed) \texttt{xt}LTL\textsubscript{f} unary operator returns all the events $\sigma^i_j$ witnessing the satisfaction of an activation, target, or correlation condition being returned by a downstream operator as an intermediate result $\rho$, while $\Next\varphi$ will simply increment the internal time counter over $\varphi$ thus determining the time from which assess the specification in $\varphi$.

Due to this structural discrepancy in the order of computation, \texttt{xt}LTL\textsubscript{f} must distinguish between \textit{timed} operators (assessing the occurrence of a specification sub-expression anytime in the trace) from the \textit{untimed} operators (determining the properties holding from the beginning of the trace). The aforementioned \texttt{xt}LTL\textsubscript{f} operator can be therefore expressed as follows:
\[\textsf{Next}^\tau(\rho)=\Set{\braket{i,j-1,L}|\braket{i,j,L}\in\rho,j>0}\]
This operator can then be computed in linear time over the size of $\rho$, i.e., $O(|\rho|)$.
On the other hand, the timed negation operator $\textsf{Not}^\tau(\rho)$ subtracts from the universal relation being the \textsf{ActivityTables} all the events appearing in $\rho$ while still guaranteeing to return the records in ascending order for trace and event id. Given $\epsilon$ the maximum trace length, this operator takes at most $O(|\LOG|\epsilon)$ time by assuming $|\rho|\ll |\LOG|\epsilon$. The globally timed operator prescribes to return a $\braket{i,j,L}\in\rho$ if also all the subsequent events within the same trace are in $\rho$, and can be computed in $O(|\rho| \log|\rho|)$ time by starting scanning the events from the last occurring in the trace.  

\paragraph{Binary Operators.} We now stress further differences between \texttt{xt}LTL\textsubscript{f} and LTL\textsubscript{f} in terms of binary operators. While \texttt{xt}LTL\textsubscript{f} can  express dataful matching conditions between activation and target conditions,  LTL\textsubscript{f} can only express properties associated with one single event.
In these regards, timed logical conjunction ($\textsf{And}^\tau_\Theta(\rho,\rho')$) extended with a binary match condition $\Theta$ over the event's payloads can be expressed as a nested $\theta$-join returning the records from both operands having the same trace id and event id, while all the pairs of witnessed events satisfying an activation $A(i)$ and target $T(j)$ conditions from the matching record shall satisfy the $\Theta$ matching condition when provided: the matching is then registered with a $M(i,j)$. Timed logical disjunction ($\textsf{Or}^\tau_\Theta(\rho,\rho')$) can be similarly expressed through a full outer $\Theta$-join. Given that the ActivityTable is pre-sorted at indexing time, we can efficiently implement such algorithms through sorted joins. As these can be computed with a joint linear scan of both operands, both operators have at most a time complexity in $O(|\rho|+|\rho'|)$. The timed until operator ($\textsf{Until}^\tau_{\textbf{True}}(\rho,\rho')$) for $\Theta=\textbf{true}$ is defined similarly to the corresponding LTL\textsubscript{f} operator: it returns all the events within a given log trace in the second operand having and the events from the first operand if all the immediately following events until the first occurrence of an event in the second operand also belong to the first:
		\[\begin{split}
\footnotesize 			\textsf{Until}^\tau_\textbf{True}(\rho,\rho')=\rho'\cup \{\footnotesize\langle i,k,L\cup L'\rangle |&\exists j>k. \braket{i,j,L}\in\rho', \\
&(\forall k\leq h<j. \braket{i,h,L'}\in\rho) \}
\end{split}\]
This can be computed in $O(|\rho|^2|\rho'|)$ time in its worst-case scenario.
 The in-depth discussion concerning the formal definition of such an operator when matching a non-trivially true matching condition $\Theta$ is deferred due to its technicalities and can be retrieved from the original paper \cite{info14030173}.
\bigskip

\subsection{Algebraic Specification for Queries}\label{timecompl}
\textit{We now compare \texttt{xt}LTL\textsubscript{f} with other long-standing definitions of temporal operators regarding database temporal representations.} 

Concerning Allen's algebra for temporal intervals \cite{10.1145/182.358434}, we can \textit{first} see that such algebra considers events as temporal intervals that might also be overlapping, while \texttt{xt}LTL\textsubscript{f} inherits the same assumptions from LTL\textsubscript{f} and considers events as pointwise and non-overlapping activities. \textit{Secondly}, while the former only supports conditions on the activity labels, \texttt{xt}LTL\textsubscript{f} also supports predicating on the conditions for the payload values (expressed as key-value pairs) associated with the specific events \cite{info14030173}, as well as supporting binary predicates to be tested across activated and targeted conditions similarly to $\theta$-joins. Recent extensions of this algebra aimed at supporting single data conditions over single events \cite{DBLP:books/sp/22/MurillasRA22}. \textit{Thirdly}, such algebra only expresses temporal correlations between two single events, albeit expressed with a duration and a termination time, and can predicate neither the eventuality nor the necessity of some properties to occur in a trace (e.g., globally and future) from a given instant in time.

Concerning the temporal relational algebra \cite{DBLP:conf/cikm/Wang95} defined over temporal relational databases (referred to as \textit{temporal modules} \cite{DBLP:journals/isci/WangJS95}),  such algebra mainly proposes timestamp transformation operations as well as windowing functions, thus retaining the entities and relationships occurring within a window time frame. Despite time being considered as a first citizen within these operators, no operator temporally correlates entities at different timestamps while also requiring the eventuality or the necessity for a specific condition within a given lapse of time. Please observe that LTL\textsubscript{f} temporal requirements cannot be expressed in traditional relational algebra without aggregation operators while not naturally assuming a columnar database storage. Therefore, this algebra cannot be directly be exploited to predicate about the necessity or the eventuality of a given event to occur without any further extension.

For all these considerations, our proposed algebra resembles more BAT from MonetDB \cite{IdreosGNMMK12,DBLP:journals/pvldb/BonczMK09}, where the intermediate result output for each operator records the table's record being selected without necessarily carrying out values stored within the specific row. Given the specificity of our scenario, our intermediate results carry the trace id and the event id as unique record identifiers. We further had to extend this representation to possibly carrying out the activated and targeted events as witnesses of the computation's correctness, providing explainable justifications for the computation, and correctly expressing $\Theta$ predicates over dataful logs. \texttt{xt}LTL\textsubscript{f} then provides a required extension of such representation for new computation needs.

%unique record identifiers are split into two distinct identifiers, a trace id and an event id. Nevertheless, this representation had to be extended due to the correlation conditions expressible in Declare, where any two events in the trace might have been correlated temporally. This therefore required the aforementioned extension of witnessing events within the intermediate representation format.



\section{Proposed Derived Operators}\label{sec:opdef}
\textit{Similarly to the definition of the derived operators in relational algebra, we now provide the definition of our proposed operators extending \texttt{xt}LTL\textsubscript{f} by expressing those in terms of the ones already known in such a temporal algebra. These are then defined in \cref{AAF,AAW,eq:andNext,lastEQ}. %The next section will provide greater details on how such operators, being here formalised in terms of existing operators for simplicity's sake, can be actually implemented as self-standing operators from scratch.
}
\medskip

\paragraph{AndAltFuture.} We want this operator to seek all the instants of time when an event activates the Declare clause while the target immediately follows while requiring that no further activation occurs between these two events. This operator aims  to optimise the \textsf{AltResponse(A,B)} clause and can be then expressed in terms of basic \texttt{xt}LTL\textsubscript{f} operators as follows:
\begin{equation}\label{AAF}
\textsf{AndAltFuture}^\tau_\Theta(\rho,\rho')\eqdef\textsf{And}^\tau_\Theta(\rho,\textsf{Next}(\textsf{Until}^\tau_\textbf{True}(\textsf{Not}^\tau(\rho),\rho')))
\end{equation}
By implementing this operator from scratch, we want to avoid running the costly computation of the timed \textsf{Until}$^\tau$ unless the activation condition associated with the intermediate result returned as $\rho$ is satisfied. Furthermore, we want to avoid explicitly computing the negation of the activation condition and express this by explicitly checking that, given any activating event in $\sigma^i_j$ in $\rho$ with an immediately following targeting one $\sigma^i_{k}$ in $\rho'$ with $|\sigma^i|>k>j$, no other events $\sigma^i_{j+h}$ in $\rho$ with $j+h<k$ shall occur. We can then express the aforementioned Declare clause in terms of the recently defined operator as follows:
\begin{equation}\label{qp1}
\textsf{Globally}^\tau(\textsf{Or}^\tau_\textbf{True}(\textsf{Not}^\tau(\rho),\textsf{AndAltFuture}^{\tau}_{\textbf{True}}(\rho,\rho')))
\end{equation}
where $\rho=\textsf{Activity}^{\LOG,\tau}_A(\textsf{A})$ and $\rho'=\textsf{Activity}^{\LOG,\tau}_T(\textsf{B})$ under the dataless assumption.
\medskip

\paragraph{AndAltWFuture.} Reflecting upon the definition of \textsf{AltPrecedence\-(A,B)} which this operator is aiming to optimise, we can observe that this might provide even greater optimisation, as we might as well avoid checking the global absence of \textsf{A}-labelled events if no \texttt{B} occurs in a trace after an \textsf{A}. Therefore, this operator acts as an extension of the former by either requiring an alternate occurrence between activation and target condition as previously or requiring the absence of any future activation if no targeting event is expected to occur. $\textsf{AndAltWFuture}^\tau_\Theta(\rho,\rho')$ can be then defined as follows:
\begin{equation}\label{AAW}
\begin{split}
\textsf{And}^\tau_\Theta(&\rho,\\
&\textsf{Next}(\textsf{Or}^\tau_\textbf{True}(\textsf{Until}^\tau_\textbf{True}(\textsf{Not}^\tau(\rho),\rho'),\textsf{Globally}^\tau(\textsf{Not}^\tau(\rho)))))
\end{split}
\end{equation}
We can now express \textsf{AltPrecedence(A,B)} by replacing, in the original \texttt{xt}LTL\textsubscript{f} Declare semantics, the previous equation with the currently introduced operator, thus obtaining:
\begin{equation}\label{qp2}
    \begin{split}
\textsf{Or}^\tau_{\textbf{True}}(&\textsf{Until}^\tau(\textsf{Not}^\tau(\rho'),\rho)\\
&\textsf{Globally}^\tau(\textsf{Or}^\tau_\textbf{True}(\textsf{Not}^\tau(\rho),\textsf{AndAltWFuture}^{\tau}_{\textbf{True}}(\rho,\rho')))\\
\end{split}
\end{equation}
\medskip

\paragraph{AndNext.} This operator aims to optimise the \textsf{ChainResponse} operator by reducing the data access to just seeking the activation condition. This makes this operator intrinsically unary, as the target condition as both in terms of data predicate and activity label has to be provided as additional arguments for the operator alongside the $\Theta$ correlation condition for dataful scenarios. To check whether the target condition occurs immediately after the operand's current event, we need to check whether it is associated with an activity table and whether it satisfies a predicate $q$. This can be then expressed in \texttt{xt}LTL\textsubscript{f} in terms of the following derived operator:
\begin{equation}\label{eq:andNext}
\textsf{AndNext}^\tau_{\textsf{B},q,\Theta}(\rho)\eqdef\textsf{And}^\tau_\Theta\left(\rho,\textsf{Next}^\tau(\textsf{Atom}^{\LOG,\tau}_{T}(\textsf{B},q))\right)
\end{equation}
At this stage, we can then express the semantics associated to the Declare template \textsf{ChainResponse(A,B)} as follows:
\begin{equation}\label{qp3}
    \textsf{Globally}^\tau(\textsf{Or}^\tau_\textbf{True}(\textsf{Not}^\tau(\rho),\textsf{AndNext}^{\LOG,\tau}_{B,\textbf{True},\textbf{True}}(\rho)))
\end{equation}
where $\rho=\textsf{Activity}^{\LOG,\tau}_A(\textsf{A})$ in a dataless scenario.
\medskip


\paragraph{NextAnd.} The second operator aims at optimising \textsf{ChainPrecedence(A,B)} similarly to the previous one, but with a swapped temporal occurrence. Please observe that negating the fact that an event shall occur after another can be expressed in terms of all the events occurring at the end of a trace and all of the events not matching the activation condition a when occurring in a non-first position. So, ChainPrecedence is usually represented as:
\[\begin{split}
\textsf{Globally}^\tau(\textsf{Or}^\tau_\textbf{True}(&\textsf{Or}^\tau_\textbf{True}(\textsf{Last}^{\LOG,\tau},\textsf{Next}^\tau(\textsf{Not}^\tau(\rho))), \\
&\textsf{And}^\tau_\textbf{True}(\textsf{Next}^\tau(\rho),\rho')))
\end{split}\]
where $\rho=\textsf{Activity}^{\LOG,\tau}_A(\textsf{A})$ and $\rho'=\textsf{Activity}^{\LOG,\tau}_T(\textsf{B})$ in a dataless scenario. After compactly representing the subexpression in the second row of the previous definition as follows:
\begin{equation}\label{lastEQ}
\textsf{NextAnd}^\tau_{\textsf{B},q,\Theta}(\rho)\eqdef\textsf{And}^\tau_\Theta\left(\textsf{Next}^\tau(\rho),\textsf{Atom}^{\LOG,\tau}_{T}(\textsf{B},q)\right)
\end{equation}
 we %then therefore substitute it with this newly-defined derived operator.\medskip
aim to optimise this last declarative clause by using this last introduced operator as follows:
\begin{equation}\label{qp4}
    \begin{split}
\textsf{Globally}^\tau(\textsf{Or}^\tau_\textbf{True}(&\textsf{Or}^\tau_\textbf{True}(\textsf{Last}^{\LOG,\tau},\textsf{Next}^\tau(\textsf{Not}^\tau(\rho))), \\
&\textsf{And}^\tau_\textbf{True}(\textsf{NextAnd}^\tau_{\textsf{B},\textbf{True},\textbf{True}}(\rho))))
\end{split}
\end{equation}
Please observe that the intended optimization induced by these operators can be considered as non-trivial, as these do not directly subsume the entire \texttt{xt}LTL\textsubscript{f} semantics associated to a template, rather than optimising a specific part.


\section{Algorithmic Implementation}\label{sec:algos}
\textit{We  discuss the implementation of the previously-introduced operators outlined in Algorithm \ref{algo:fdgt}, thus justifying their definition as novel derived operators. For each of them, we briefly discuss their computational complexity and compare it to the expected theoretical speed-up not considering the cost of memory allocation and page-faults.}\medskip

%%%%%%%%%%%%%
\begin{algorithm}[!t]
	\begingroup % trick algorithm2e into thinking we're in one column mode
	\csname @twocolumnfalse\endcsname
	\noindent
	\resizebox{\textwidth}{!}{%
		\begin{minipage}{1.4\textwidth}
\begin{algorithmic}[1]


\Function{AndAltFuture$^\tau_\Theta$}{$\rho,\rho'$}
\ForAll{$\braket{i,j,L},\braket{i,k,L'}\in (\rho\times \rho')$ \textbf{s.t.} $j< k$ }\label{actualLinearScan}

\If{$\not\exists h>0. \braket{i,j+h,L}\in\rho$ \textbf{s.t.} $j+h<k$ }\label{notActivation1}
%\State {$L''\gets \bigcup\{\tilde{L}|\braket{i,h,\tilde{L}}\in\rho',h\geq k\}$}
\If{$L'\neq\emptyset$ \textbf{and} $L\neq\emptyset$ \textbf{and} $\Theta\neq \textbf{True}$}
\State $L''\gets\{M(j',k')|\Theta(\sigma^i_{j'},\,\sigma^i_{k'}),A(j')\in L, T(k')\in L'\}$
\State \algorithmicif\; $L''\neq\emptyset$ \algorithmicthen\; \textbf{yield} $\braket{i,j,L''}$\label{matchingForEvents}
\Else\; \textbf{yield} $\braket{i,j,L\cup L''}$\label{morcheeba}
\EndIf
\EndIf
\EndFor
\EndFunction
\Statex
\Function{AndAltWFuture$^\tau_\Theta$}{$\rho,\rho'$}
\ForAll{$\braket{i,j,L} \in \rho$  }
\ForAll{$\braket{i,k,L'}\in \rho'$ \textbf{s.t.} $j\leq k$}
\If{$\not\exists h>0. \braket{i,j+h,L}\in\rho$ \textbf{s.t.} $j+h<k$ }\label{notActivation2}
\State \algorithmicif\; $j=|\sigma^i|-1$ \textbf{continue};
%\State {$L''\gets \bigcup\{\tilde{L}|\braket{i,h,\tilde{L}}\in\rho',h\geq k\}$}
\If{$L\neq\emptyset$ \textbf{and} $L'\neq\emptyset$ \textbf{and}  $\Theta\neq \textbf{True}$}
%\State $L''\gets\{M(j,k+h)|\Theta(\sigma^i_{j'},\,\sigma^i_{k+h}),A(j')\in L, T(k+h)\in L''\}$
\State $L''\gets\{M(j',k')|\Theta(\sigma^i_{j'},\,\sigma^i_{k'}),A(j')\in L, T(k')\in L'\}$
\State \algorithmicif\; $L''\neq\emptyset$ \algorithmicthen\; \textbf{yield} $\braket{i,j,L''}$
\Else\; \textbf{yield} $\braket{i,j,L\cup L''}$
\EndIf
\EndIf
\EndFor
\If{$\not\exists k,h. \braket{i,k,L'}\in \rho'\wedge \braket{i,h,L''}\in \rho\wedge j< k,j<h$}\label{weakness}
\State \textbf{yield} $\braket{i,j,L}$\label{withAbsenceActivationOnwards}
\EndIf
\EndFor
\EndFunction

\Statex
\Function{AndNext$^\tau_{\textsf{B},q,\Theta}$}{$\rho$}
\State \algorithmicif\; $\not\exists \sigma^i\in\LOG,\sigma^i_j\in\sigma^i. \lambda(\sigma^i_j)=\textsf{B}$ \algorithmicthen\;\Return $\emptyset$\label{countScan}
\ForAll{$\braket{i,j,L}\in \rho$ \textbf{s.t.} $j<|\sigma^i|-1$ \textbf{and} $\lambda(\sigma^i_{j+1})=\textsf{B}$ }\label{firstCond}
\State $L'\gets L\cup\{T(j+1)\}$
\If{$\Theta\neq\textbf{True}$}
\State \algorithmicif\; $L\neq\emptyset$ \textbf{and} $\not\exists A(k)\in L. \theta(\sigma^i_k,\,\sigma^i_{j+1})$ \algorithmicthen\; \textbf{continue}
\State \algorithmicelse\; $L'\gets \{M(k,j+1)|A(k)\in L\}$\label{hasMatch1}
\EndIf
\State \algorithmicif\; $q\neq\textbf{True}\vee q(\sigma^i_{j+1})$ \algorithmicthen\; \textbf{yield} $\braket{i,j,L'}$ \label{actualReturn1}
\EndFor
\EndFunction
\Statex
\Function{NextAnd$^\tau_{\textsf{B},q,\Theta}$}{$\rho$}
%\State \algorithmicif\; $\not\exists \sigma^i\in\LOG,\sigma^i_j\in\sigma^i. \lambda(\sigma^i_j)=\textsf{B}$ \algorithmicthen\;\Return $\emptyset$
\ForAll{$\braket{i,j+1,L}\in \rho$ \textbf{s.t.} $j\geq 0$ \textbf{and} $\lambda(\sigma^i_{j})=\textsf{B}$ }
\State $L'\gets L\cup\{T(j)\}$
\If{$\Theta\neq\textbf{True}$}
\State \algorithmicif\; $L\neq\emptyset$ \textbf{and} $\not\exists A(k)\in L. \theta(\sigma^i_k,\,\sigma^i_{j})$ \algorithmicthen\; \textbf{continue}
\State \algorithmicelse\; $L'\gets \{M(k,j)|A(k)\in L\}$
\EndIf
\State \algorithmicif\; $q\neq\textbf{True}\vee q(\sigma^i_{j})$ \algorithmicthen\; \textbf{yield} $\braket{i,j+1,L'}$
\EndFor
\EndFunction

\end{algorithmic}
		\end{minipage}%
	}% <------------- end of \resizebox
	\endgroup


 \caption{Newly proposed \texttt{xt}LTL\textsubscript{f} operators.}\label{algo:fdgt}
\end{algorithm}
\paragraph{AndAltFuture.} We now scan each operand, $\rho$ and $\rho'$, in linear time similarly to the timed \textit{and} operator, despite this being expressed in pseudocode with a cross product for simplifying the overall notation (L. \ref{actualLinearScan}). We then consider all the events in the same trace having no immediate subsequent event in $\rho$ prior to the occurrence of the next event in $\rho'$: this can be simply checked in $\rho$ by determining that the next record appearing in $\rho$ after $\braket{i,j,L}$ has an event id less than $k$ (L. \ref{notActivation1}). If there is a non-trivially true $\Theta$ predicate, we also impose that at least one activation occurring after or at $\sigma^i_j$ and at least one target occurring after or at $\sigma^i_k$ matches with $\Theta$ (L. \ref{matchingForEvents}). Otherwise, we compute no match, and we straightforwardly collect the activation and target conditions from both events (L. \ref{morcheeba}). In the code, we explicitly injected an early-stopping condition avoiding testing subsequent events in $\rho'$ within the same trace as soon as we detect one event in $\rho$, invalidating the condition at L. \ref{notActivation1}. By considering the time complexities for each \texttt{xt}LTL\textsubscript{f} operator in \S\ref{timecompl}, we can argue that the time complexity associated with computing this operator as in the previous section without the aforementioned computation is totalled to $O(|\rho|+(||\LOG||-|\rho|)^2|\rho'|+2((||\LOG||-|\rho|)+|\rho'|))$, where $||\LOG||=|\LOG|\epsilon$. On the other hand, by assuming to always scan each trace quadratically of length $\epsilon$ for each event in $\rho$, we obtain the time complexity of $O(|\rho|\sfrac{\epsilon^2}{2}+|\rho'|)$ for the derived operator when implemented as per the previous discussion. If we assume that $\rho$ and $\rho'$ are associated with a single activity label as per the scenario in Declare where the number of events, we can derive that the provided algorithm always provides a positive speed-up if compared to the original formulation in Eq.\ref{AAF}. \medskip

\paragraph{AndAltWFuture.} This algorithm works similarly to the previous, where we relax the until condition with a weak until, thus also admitting an absence of activation conditions after the first occurrence if no further target event are present (L. \ref{weakness}). Even in this scenario, we have a similar time complexity to the previous, while the original formulation in Eq. \ref{AAW} introduced an additional overhead to the previous by computing an additional timed disjunction and the computation of a globally over the negation of the possibly activating events. Therefore, we expect even greater speed up for this latest operator.   \medskip

\paragraph{AndNext.} As previously observed in the formal definition of this operator, we transformed this into an unary operator where, instead of retrieving two sets of events associated with two activity labels, we just scan one of the two. Before starting any form of scan, we immediately return if, after a $O(|\LOG|)$ scan of the CountTable, we detect that no event is associated with the target condition (L. \ref{countScan}). Otherwise, we consider only events both coming from traces containing an event with  activity label \texttt{B} and not being at the end of the trace, and which immediately next event is associated to an activity label \textbf{B} as a target condition ($T(j+1)$, L. \ref{firstCond}); we implementationally further enhanced this by completely skipping any test whether the event resides in a trace where no \texttt{B} event resides. If $\Theta\neq\textbf{True}$, then we also have to guarantee that each activation condition appearing in $\rho$ should match with the target event at time $j+1$ (L. \ref{hasMatch1}) and, upon provision of $q$, the target condition should also match with this (L. \ref{actualReturn1}). The computational complexity of this operator is in $O(|\rho|+|\LOG|)$ and, if we are taking into account the accessing time to the immediately following event if any, we obtain a time in $2|\rho|+|\LOG|$. If compared to the time complexity of Eq. \ref{eq:andNext} of $|\rho|+2|\rho'|$, we then obtain a positive speed up, i.e. $\frac{|\rho|+2|\rho'|}{2|\rho|+|\LOG|}\geq 1$, for $|\rho'|>\sfrac{|\rho|}{2}$ and $0<|\LOG|<2|\rho'|+|\rho|$.  \medskip

\paragraph{NextAnd.} This other operator works similarly to the previous, where we are checking instead the immediately preceding event instead of looking at the immediately following one, thus requiring that each element of interest in $\rho$ shall never be at the beginning of the trace. The same considerations over speed-up and time complexity follow from the previous algorithm. %, thus obtaining a positive speed-up with $\frac{|\rho|+2|\rho'|}{2|\rho|}\geq 1$ for $0<|\rho|\leq 2|\rho'|$ and $|\rho'|>0$.  
\medskip

After associating each of the novel operators the aforementioned algorithmic implementation,  \cref{qp1,qp2,qp3,qp4} will then provide the semantics generating the query plan as \texttt{Proposed} in this current paper, while the direct translation of the LTL\textsubscript{f} expressions in \tablename~\ref{tab:dt} to the operators outlined in \S\ref{xtltlf} provides the \texttt{Original} formulation of the query plan also in \cite{info14030173} where none of the previous algorithms is used.



%we then generate a new query plan, where the sub-expressions from Eq. \ref{AAF}-\ref{lastEQ} were completely replaced with the corresponding \texttt{xt}LTL\textsubscript{f} operators and associated algorithms discussed in this section, we then kept the original declarative semantics from (\texttt{Original}) with the one proposed in this paper (\texttt{Proposed}).


\section{Empirical Evaluation}\label{sec:empeval}

\begin{figure*}[!t]
\centering
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{images/BrokerPDF.png}
\caption{FoodBroker dataset}\label{fbPDF}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{images/HospitalPDF.png}
\caption{Hospital dataset}\label{hPDF}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{images/CyberPDF.png}
\caption{Cybersecurity dataset}\label{cPDF}
\end{subfigure}
\caption{Sampled probability density function associated with the length of the traces for each sub-log extracted from each original dataset.}\label{fig:PDF}
\end{figure*}\begin{figure*}[!p]
\centering
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{images/FoodBroker.png}
\caption{FoodBroker dataset}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{images/Hospital.png}
\caption{Hospital dataset}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{images/Cyber.png}
\caption{Cybersecurity dataset}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{images/Speedups.png}
\caption{Datasets' Speedup: (\textit{left}) FoodBroker, (\textit{center}) Hospital, and (\textit{right}) Cybersecurity.}
\end{subfigure}
\caption{Comparing the proposed implementation of the derived operators with the previous implementation given in KnoBAB. }\label{overallBenchmarks}
\end{figure*}
\textit{Given that the aim of our derived operators is to enhance formal verification tasks conducted over temporal clauses expressed in Declare, we compare the different running times of carrying out formal verification tasks over our previous set of operators as well as by replacing those with our currently proposed derived ones. We discard from our evaluation the benchmark of the single operator, as this is insufficient to remark on their adequacy in outperforming our previous implementation. Thus, we compare different query plans being generated from different Declare semantics being specified at runtime through the \texttt{queryplan "name" \{} ... \texttt{\}} query.  %benchmark the time required for formal verification tasks when such clauses are used rather than benchmarking the running time for each operator. In fact, given the overall pipeline, we might overall provide an optimisation for such a task providing a minimal overhead to the overall query plan computation. Therefore, 
With this, achieving a positive speed-up by using the proposed operators will tell us that, under specific data conditions, the original \texttt{xt}LTL\textsf{f} query plan associated with the declarative clauses available in KnoBAB constitutes the major computational bottleneck. Having a negligible speed-up will likely remark  other components in the query plan dominate the overall running time, while having a negative speed-up only on specific data conditions will motivate some future work on hybrid algorithms, thus allowing to choose between different algorithms for specific temporal operators depending on the data distribution within the loaded dataset \cite{DBLP:journals/spe/Musser97}.} \medskip


Our benchmarks exploited a Dell Mobile Precision Workstation 5760 on Ubuntu 22.04: Intel® Xeon(R) W-11955M CPU @ 2.60GHz $\times$ 16, 64GB DDR4 3200MHz RAM. We took two real-world datasets and a synthetic one for our experiments, both being dataless. The first real dataset (\texttt{Hospital}) monitors the patient flow and different medical procedures to which the patients in question were subjected; each trace tracks a single patient from his hospitalisation to their dismissal, and each activity label describes the name associated to such phases \cite{https://doi.org/10.4121/uuid:d9769f3d-0ab0-4fb8-803b-0d1120ffcf54}. The second one (\texttt{Cybersecurity}) provides the auditing step of different malware, where each trace represents  a single malware being audited while each activity label identifies one single system call event being audited as invoked by the malware \cite{10.7717/peerj-cs.346,DBLP:conf/siu/YaziCG19}.  The synthetic dataset was derived from temporal graphs generated by \texttt{FoodBroker} \cite{DBLP:conf/wbdb/PetermannJMR14} while describing trades and shipments of goods  mediated by a brokerage company. For each \textit{GraphTransaction}, we sort all the vertices describing an event occurring at a specific \texttt{date}, thus also including  \texttt{creation} timestamps. For vertices describing a ticket being filed by a client raising a complaint, we return an activity label associated with the type of complaint (\texttt{problem}); otherwise, we keep the original vertex label. We then collect the set of temporally ordered activity labels and represent those as log traces. The updated FoodBroker codebase for generating event logs is also available online\footnote{\url{https://github.com/jackbergus/foodbroker/}}.


For each dataset, we then obtain the sampled trace length distribution, and we sample sub-logs of various sizes while trying to abide by the trace distribution from the original dataset, notwithstanding their skewness. For the first and third (or second) datasets, we sample the logs so that their sizes are powers of ten (or nine) while always guaranteeing that each sub-log $|\LOG_h|=10^h$ (or $|\LOG_h|=9^h$) is always a subset of any larger sub-log. We also keep the original log as the last sample dataset. This random sampling mechanism is required better to assess the scalability of the proposed operator's implementation while guaranteeing an approximation of the original trace length distribution across the board to guarantee similar running time conditions. \figurename~\ref{fig:PDF} reports the sample PDF trace length for each of the sampled logs alongside the size of each sample. The \texttt{FoodBroker} synthetic dataset contains the shorter traces (\figurename~\ref{fbPDF}): all the sampled logs except the first one have a maximum trace length of $24$, while the first sublog has a maximum trace length of $21$. On the other hand, the first two smaller log samples of the real-world \texttt{Hospital} dataset (\figurename~\ref{hPDF}) have traces with a maximum length of $1200$, while the remaining two have a maximum trace length of $1814$. The \texttt{Cybersecurity} dataset (\figurename ~\ref{cPDF}) contains the longest traces by having the maximum trace length of $1.23\cdot10^6$ for the smaller two sub-logs and of $1.76\cdot 10^6$ for the remaining ones. This information will soon become relevant while conducting our following analysis of the algorithmic speed-ups given by our proposed derived operators while performing formal verification over the models described in the following paragraph.


 Given that we aim to test these newly introduced \texttt{xt}LTL\textsubscript{f} operators in the context of a Declare-based formal verification task when \texttt{xt}LTL\textsubscript{f} is used to represent its semantics, we generate four specifications $\Phi^c_1,\dots,\Phi^c_4$ for each declarative clause of interest $c$, \texttt{AltPrecedence}, \texttt{AltResponse}, \texttt{ChainPrecedence}, and \texttt{ChainResponse}, where each $\Phi^c_i$ contains exactly $i$ binary clauses instantiated by instantiating each activity label from the most frequently-occurring ones within the smaller sublog. We then use the same specifications generated for the smaller log and the greater sub logs, thus comparing running experiments with the same specifications. The resulting logs and specifications are freely available online\footnote{\url{https://osf.io/6y8cv/?view_only=3b8c01761fcf4941ad726aba4101151e}}. \medskip

With reference to \figurename~\ref{overallBenchmarks}, AndAlt\ding{83} operators %are the ones being more 
consistently outperform our previous Declare query plan  as they lead to an associated speed-up  always strictly greater than one. Our previous definition of the Declare operators is greatly affected by the number of clauses within the model, which becomes even more apparent when the maximum and average trace length $\epsilon$ per sampled log increases. On the other hand, running our former formal verification query plan for AndAlt\ding{83} clauses  over the Cybersecurity dataset always took more than one 1H ($3.6\cdot 10^6$ ms), thus remarking an increased running time for the original query plan strategy when longer traces occur. We stopped recording the running time, as the overhead introduced by the intermediate operators for carrying out the actual matching between activation and target conditions was strikingly evident while our proposed operators could instead carry out the formal verification task within one minute. Although no out-of-memory exceptions were observed before the timeout, these were clearly observed in larger specifications and log sizes, thus clearly remarking KnoBAB's limits as a main memory engine by not persisting the query intermediate results in secondary memory. Despite the code allowing the clearing of intermediate caches to be run to free extra memory, this only partially addresses the out-of-memory failure for larger specifications. %We also obtain similar out-of-memory errors by giving the original operators a sufficient amount of time to compute. 
Overall, this remarks that this proposed extension for AndAlt\ding{83} operators outperforms our previous query plan definition, as also expected from our previous analysis concerning the overall theoretical time complexity.


Chain\ding{83} operators provide a more convoluted scenario to be examined carefully. First, we observe a clear trend correlating dataset with longer traces with an overall increase in speed-up. In fact, the \texttt{Hospital} datasets exhibit more speed-ups compared to the \texttt{FoodBroker} one, where the recently proposed operators yield comparable or underperforming running times. Notwithstanding the former, we can clearly observe that the recently proposed operators consistently outperform our previous solution over the \texttt{Cybersecurity} dataset. Differently from our previous set-up, we can now observe that the original formulation of the declarative clauses without the currently presented operators now goes out of memory before hitting the 1H timeout for the larger sample being the full dataset, while our solution still manages to carry out some temporal formal verification tasks over specifications containing fewer clauses. Last, we consistently observe that such operators still provide greater speed-ups over datasets with smaller log sizes, thus providing theoretical validation to our speed-up equations for such operators. This postulates the need for such operators while dealing with massive datasets while advocating the usage of hybrid algorithms for switching between the previous solution and the currently proposed one.


%\texttt{\color{red}[TODO: mainly discuss the experiments' outcome]}

\section{Conclusions and Future Works}
This paper proposes an extension to our previous work on KnoBAB by optimising our previously proposed query plan by introducing novel algebraic temporal operators expressing formal verification tasks on column database storages in main memory. As a consequence, we extended our temporal algebra \texttt{xt}LTL\textsubscript{f} with four novel operators, subsuming entire \texttt{xt}LTL\textsubscript{f} expressions which before could be only represented in terms of combinations of costly basic operators. %This is addressed through the definition of novel derived operators, that is, operators that can be expressed as a combination of already-existing \texttt{xt}LTL\textsubscript{f} operators being a calque of the customary LTL\textsubscript{f} operators. 
Preliminary results over such operators provide non-negligible speed-up to the formal verification tasks over realistic datasets, where several events are audited and collected in a larger collection of traces.

Despite these experiments remark the efficiency of carrying out formal verification computations on columnar databases implemented as a main memory engine, the consistent out-of-memory faults that we experienced over larger collections of data containing more events (i.e., longer traces) encourage us to store the intermediate query results in secondary memory, as customary for off-the-shelf databases such as PostgreSQL. We see this as the last required step for fully supporting real data alongside the orthogonal operator optimization as discussed in the present paper. Despite putting this solution in place will come to the detriment of overall performances, this will guarantee the carriage of the entire computation. This drawback might be alleviated by determining at runtime whether to represent intermediate results in primary or secondary memory depending on the log and trace size. Another possible way to alleviate such problem is to re-implement the overall pipeline using a pull-based strategy \cite{DBLP:books/x/dittrich2016} when operations are not run concurrently. 

The current experiment noted the optimality of the proposed operators when dealing with datasets with longer traces (i.e., greater $\epsilon$). Future work will consider the possibility of defining hybrid algorithms \cite{4567924} over the operators optimising Chain\ding{83} clauses  by empirically determining the table size threshold over which prefer the derived operators over the original. As an orthogonal approach, we will also define the ``dual'' operators for \texttt{AndNext} and \texttt{NextAnd} so as to start scanning from the target condition while moving backwards towards any existing activation condition when the number of targets is deemed to be fewer than the activations. 

Our future works will also aim to further benchmark these operators in a context of \textit{dataful} logs, where events are also associated with a payload expressed as a key-value pair as in customary semi-structured data formats. These works will then outline the overhead required to compute a $\Theta$ correlation condition between activation and target event. 

Finally, an interesting outcome of these observations on relational databases would be the application of such an algebra in the context of temporal graphs 
\cite{DBLP:journals/vldb/RostGTFSCAJR22}, thus enabling the efficient temporal verification under this different data representation. Despite the recent attempt at representing logs as temporal graphs \cite{olaf}, the aforementioned is still a \textit{desideratum}, as no graph temporal operator for expressing formal verification tasks is currently known. Differently from the previously pursued approach \cite{DBLP:conf/medi/ZakiHH022}, this will then require to define tailored temporal operators for graph query languages similarly to \texttt{xt}LTL\textsubscript{f}.




%
%ACM's consolidated article template, introduced in 2017, provides a
%consistent \LaTeX\ style for use across ACM publications, and
%incorporates accessibility and metadata-extraction functionality
%necessary for future Digital Library endeavors. Numerous ACM and
%SIG-specific \LaTeX\ templates have been examined, and their unique
%features incorporated into this single new template.
%
%If you are new to publishing with ACM, this document is a valuable
%guide to the process of preparing your work for publication. If you
%have published with ACM before, this document provides insight and
%instruction into more recent changes to the article template.
%
%The ``\verb|acmart|'' document class can be used to prepare articles
%for any ACM publication --- conference or journal, and for any stage
%of publication, from review to final ``camera-ready'' copy, to the
%author's own version, with {\itshape very} few changes to the source.

%\section{Template Overview}
%As noted in the introduction, the ``\verb|acmart|'' document class can
%be used to prepare many different kinds of documentation --- a
%double-blind initial submission of a full-length technical paper, a
%two-page SIGGRAPH Emerging Technologies abstract, a ``camera-ready''
%journal article, a SIGCHI Extended Abstract, and more --- all by
%selecting the appropriate {\itshape template style} and {\itshape
%  template parameters}.
%
%This document will explain the major features of the document
%class. For further information, the {\itshape \LaTeX\ User's Guide} is
%available from
%\url{https://www.acm.org/publications/proceedings-template}.
%
%\subsection{Template Styles}
%
%The primary parameter given to the ``\verb|acmart|'' document class is
%the {\itshape template style} which corresponds to the kind of publication
%or SIG publishing the work. This parameter is enclosed in square
%brackets and is a part of the {\verb|documentclass|} command:
%\begin{verbatim}
%  \documentclass[STYLE]{acmart}
%\end{verbatim}
%
%Journals use one of three template styles. All but three ACM journals
%use the {\verb|acmsmall|} template style:
%\begin{itemize}
%\item {\texttt{acmsmall}}: The default journal template style.
%\item {\texttt{acmlarge}}: Used by JOCCH and TAP.
%\item {\texttt{acmtog}}: Used by TOG.
%\end{itemize}
%
%The majority of conference proceedings documentation will use the {\verb|acmconf|} template style.
%\begin{itemize}
%\item {\texttt{acmconf}}: The default proceedings template style.
%\item{\texttt{sigchi}}: Used for SIGCHI conference articles.
%\item{\texttt{sigplan}}: Used for SIGPLAN conference articles.
%\end{itemize}
%
%\subsection{Template Parameters}
%
%In addition to specifying the {\itshape template style} to be used in
%formatting your work, there are a number of {\itshape template parameters}
%which modify some part of the applied template style. A complete list
%of these parameters can be found in the {\itshape \LaTeX\ User's Guide.}
%
%Frequently-used parameters, or combinations of parameters, include:
%\begin{itemize}
%\item {\texttt{anonymous,review}}: Suitable for a ``double-blind''
%  conference submission. Anonymizes the work and includes line
%  numbers. Use with the \texttt{\acmSubmissionID} command to print the
%  submission's unique ID on each page of the work.
%\item{\texttt{authorversion}}: Produces a version of the work suitable
%  for posting by the author.
%\item{\texttt{screen}}: Produces colored hyperlinks.
%\end{itemize}
%
%This document uses the following string as the first command in the
%source file:
%\begin{verbatim}
%\documentclass[sigconf]{acmart}
%\end{verbatim}
%
%\section{Modifications}
%
%Modifying the template --- including but not limited to: adjusting
%margins, typeface sizes, line spacing, paragraph and list definitions,
%and the use of the \verb|\vspace| command to manually adjust the
%vertical spacing between elements of your work --- is not allowed.
%
%{\bfseries Your document will be returned to you for revision if
%  modifications are discovered.}
%
%\section{Typefaces}
%
%The ``\verb|acmart|'' document class requires the use of the
%``Libertine'' typeface family. Your \TeX\ installation should include
%this set of packages. Please do not substitute other typefaces. The
%``\verb|lmodern|'' and ``\verb|ltimes|'' packages should not be used,
%as they will override the built-in typeface families.
%
%\section{Title Information}
%
%The title of your work should use capital letters appropriately -
%\url{https://capitalizemytitle.com/} has useful rules for
%capitalization. Use the {\verb|title|} command to define the title of
%your work. If your work has a subtitle, define it with the
%{\verb|subtitle|} command.  Do not insert line breaks in your title.
%
%If your title is lengthy, you must define a short version to be used
%in the page headers, to prevent overlapping text. The \verb|title|
%command has a ``short title'' parameter:
%\begin{verbatim}
%  \title[short title]{full title}
%\end{verbatim}
%
%\section{Authors and Affiliations}
%
%Each author must be defined separately for accurate metadata
%identification.  As an exception, multiple authors may share one
%affiliation. Authors' names should not be abbreviated; use full first
%names wherever possible. Include authors' e-mail addresses whenever
%possible.
%
%Grouping authors' names or e-mail addresses, or providing an ``e-mail
%alias,'' as shown below, is not acceptable:
%\begin{verbatim}
%  \author{Brooke Aster, David Mehldau}
%  \email{dave,judy,steve@university.edu}
%  \email{firstname.lastname@phillips.org}
%\end{verbatim}
%
%The \verb|authornote| and \verb|authornotemark| commands allow a note
%to apply to multiple authors --- for example, if the first two authors
%of an article contributed equally to the work.
%
%If your author list is lengthy, you must define a shortened version of
%the list of authors to be used in the page headers, to prevent
%overlapping text. The following command should be placed just after
%the last \verb|\author{}| definition:
%\begin{verbatim}
%  \renewcommand{\shortauthors}{McCartney, et al.}
%\end{verbatim}
%Omitting this command will force the use of a concatenated list of all
%of the authors' names, which may result in overlapping text in the
%page headers.
%
%The article template's documentation, available at
%\url{https://www.acm.org/publications/proceedings-template}, has a
%complete explanation of these commands and tips for their effective
%use.
%
%Note that authors' addresses are mandatory for journal articles.
%
%\section{Rights Information}
%
%Authors of any work published by ACM will need to complete a rights
%form. Depending on the kind of work, and the rights management choice
%made by the author, this may be copyright transfer, permission,
%license, or an OA (open access) agreement.
%
%Regardless of the rights management choice, the author will receive a
%copy of the completed rights form once it has been submitted. This
%form contains \LaTeX\ commands that must be copied into the source
%document. When the document source is compiled, these commands and
%their parameters add formatted text to several areas of the final
%document:
%\begin{itemize}
%\item the ``ACM Reference Format'' text on the first page.
%\item the ``rights management'' text on the first page.
%\item the conference information in the page header(s).
%\end{itemize}
%
%Rights information is unique to the work; if you are preparing several
%works for an event, make sure to use the correct set of commands with
%each of the works.
%
%The ACM Reference Format text is required for all articles over one
%page in length, and is optional for one-page articles (abstracts).
%
%\section{CCS Concepts and User-Defined Keywords}
%
%Two elements of the ``acmart'' document class provide powerful
%taxonomic tools for you to help readers find your work in an online
%search.
%
%The ACM Computing Classification System ---
%\url{https://www.acm.org/publications/class-2012} --- is a set of
%classifiers and concepts that describe the computing
%discipline. Authors can select entries from this classification
%system, via \url{https://dl.acm.org/ccs/ccs.cfm}, and generate the
%commands to be included in the \LaTeX\ source.
%
%User-defined keywords are a comma-separated list of words and phrases
%of the authors' choosing, providing a more flexible way of describing
%the research being presented.
%
%CCS concepts and user-defined keywords are required for for all
%articles over two pages in length, and are optional for one- and
%two-page articles (or abstracts).
%
%\section{Sectioning Commands}
%
%Your work should use standard \LaTeX\ sectioning commands:
%\verb|section|, \verb|subsection|, \verb|subsubsection|, and
%\verb|paragraph|. They should be numbered; do not remove the numbering
%from the commands.
%
%Simulating a sectioning command by setting the first word or words of
%a paragraph in boldface or italicized text is {\bfseries not allowed.}
%
%\section{Tables}
%
%The ``\verb|acmart|'' document class includes the ``\verb|booktabs|''
%package --- \url{https://ctan.org/pkg/booktabs} --- for preparing
%high-quality tables.
%
%Table captions are placed {\itshape above} the table.
%
%Because tables cannot be split across pages, the best placement for
%them is typically the top of the page nearest their initial cite.  To
%ensure this proper ``floating'' placement of tables, use the
%environment \textbf{table} to enclose the table's contents and the
%table caption.  The contents of the table itself must go in the
%\textbf{tabular} environment, to be aligned properly in rows and
%columns, with the desired horizontal and vertical rules.  Again,
%detailed instructions on \textbf{tabular} material are found in the
%\textit{\LaTeX\ User's Guide}.
%
%Immediately following this sentence is the point at which
%Table~\ref{tab:freq} is included in the input file; compare the
%placement of the table here with the table in the printed output of
%this document.
%
%\begin{table}
%  \caption{Frequency of Special Characters}
%  \label{tab:freq}
%  \begin{tabular}{ccl}
%    \toprule
%    Non-English or Math&Frequency&Comments\\
%    \midrule
%    \O & 1 in 1,000& For Swedish names\\
%    $\pi$ & 1 in 5& Common in math\\
%    \$ & 4 in 5 & Used in business\\
%    $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
%  \bottomrule
%\end{tabular}
%\end{table}
%
%To set a wider table, which takes up the whole width of the page's
%live area, use the environment \textbf{table*} to enclose the table's
%contents and the table caption.  As with a single-column table, this
%wide table will ``float'' to a location deemed more
%desirable. Immediately following this sentence is the point at which
%Table~\ref{tab:commands} is included in the input file; again, it is
%instructive to compare the placement of the table here with the table
%in the printed output of this document.
%
%\begin{table*}
%  \caption{Some Typical Commands}
%  \label{tab:commands}
%  \begin{tabular}{ccl}
%    \toprule
%    Command &A Number & Comments\\
%    \midrule
%    \texttt{{\char'134}author} & 100& Author \\
%    \texttt{{\char'134}table}& 300 & For tables\\
%    \texttt{{\char'134}table*}& 400& For wider tables\\
%    \bottomrule
%  \end{tabular}
%\end{table*}
%
%Always use midrule to separate table header rows from data rows, and
%use it only for this purpose. This enables assistive technologies to
%recognise table headers and support their users in navigating tables
%more easily.
%
%\section{Math Equations}
%You may want to display math equations in three distinct styles:
%inline, numbered or non-numbered display.  Each of the three are
%discussed in the next sections.
%
%\subsection{Inline (In-text) Equations}
%A formula that appears in the running text is called an inline or
%in-text formula.  It is produced by the \textbf{math} environment,
%which can be invoked with the usual
%\texttt{{\char'134}begin\,\ldots{\char'134}end} construction or with
%the short form \texttt{\$\,\ldots\$}. You can use any of the symbols
%and structures, from $\alpha$ to $\omega$, available in
%\LaTeX~\cite{Lamport:LaTeX}; this section will simply show a few
%examples of in-text equations in context. Notice how this equation:
%\begin{math}
%  \lim_{n\rightarrow \infty}x=0
%\end{math},
%set here in in-line math style, looks slightly different when
%set in display style.  (See next section).
%
%\subsection{Display Equations}
%A numbered display equation---one set off by vertical space from the
%text and centered horizontally---is produced by the \textbf{equation}
%environment. An unnumbered display equation is produced by the
%\textbf{displaymath} environment.
%
%Again, in either environment, you can use any of the symbols and
%structures available in \LaTeX\@; this section will just give a couple
%of examples of display equations in context.  First, consider the
%equation, shown as an inline equation above:
%\begin{equation}
%  \lim_{n\rightarrow \infty}x=0
%\end{equation}
%Notice how it is formatted somewhat differently in
%the \textbf{displaymath}
%environment.  Now, we'll enter an unnumbered equation:
%\begin{displaymath}
%  \sum_{i=0}^{\infty} x + 1
%\end{displaymath}
%and follow it with another numbered equation:
%\begin{equation}
%  \sum_{i=0}^{\infty}x_i=\int_{0}^{\pi+2} f
%\end{equation}
%just to demonstrate \LaTeX's able handling of numbering.
%
%\section{Figures}
%
%The ``\verb|figure|'' environment should be used for figures. One or
%more images can be placed within a figure. If your figure contains
%third-party material, you must clearly identify it as such, as shown
%in the example below.
%%\begin{figure}[h]
%%  \centering
%%  \includegraphics[width=\linewidth]{sample-franklin}
%%  \caption{1907 Franklin Model D roadster. Photograph by Harris \&
%%    Ewing, Inc. [Public domain], via Wikimedia
%%    Commons. (\url{https://goo.gl/VLCRBB}).}
%%  \Description{A woman and a girl in white dresses sit in an open car.}
%%\end{figure}
%
%Your figures should contain a caption which describes the figure to
%the reader.
%
%Figure captions are placed {\itshape below} the figure.
%
%Every figure should also have a figure description unless it is purely
%decorative. These descriptions convey what’s in the image to someone
%who cannot see it. They are also used by search engine crawlers for
%indexing images, and when images cannot be loaded.
%
%A figure description must be unformatted plain text less than 2000
%characters long (including spaces).  {\bfseries Figure descriptions
%  should not repeat the figure caption – their purpose is to capture
%  important information that is not already provided in the caption or
%  the main text of the paper.} For figures that convey important and
%complex new information, a short text description may not be
%adequate. More complex alternative descriptions can be placed in an
%appendix and referenced in a short figure description. For example,
%provide a data table capturing the information in a bar chart, or a
%structured list representing a graph.  For additional information
%regarding how best to write figure descriptions and why doing this is
%so important, please see
%\url{https://www.acm.org/publications/taps/describing-figures/}.
%
%\subsection{The ``Teaser Figure''}
%
%A ``teaser figure'' is an image, or set of images in one figure, that
%are placed after all author and affiliation information, and before
%the body of the article, spanning the page. If you wish to have such a
%figure in your article, place the command immediately before the
%\verb|\maketitle| command:
%\begin{verbatim}
%  \begin{teaserfigure}
%    \includegraphics[width=\textwidth]{sampleteaser}
%    \caption{figure caption}
%    \Description{figure description}
%  \end{teaserfigure}
%\end{verbatim}
%
%\section{Citations and Bibliographies}
%
%The use of \BibTeX\ for the preparation and formatting of one's
%references is strongly recommended. Authors' names should be complete
%--- use full first names (``Donald E. Knuth'') not initials
%(``D. E. Knuth'') --- and the salient identifying features of a
%reference should be included: title, year, volume, number, pages,
%article DOI, etc.
%
%The bibliography is included in your source document with these two
%commands, placed just before the \verb|\end{document}| command:
%\begin{verbatim}
%  \bibliographystyle{ACM-Reference-Format}
%  \bibliography{bibfile}
%\end{verbatim}
%where ``\verb|bibfile|'' is the name, without the ``\verb|.bib|''
%suffix, of the \BibTeX\ file.
%
%Citations and references are numbered by default. A small number of
%ACM publications have citations and references formatted in the
%``author year'' style; for these exceptions, please include this
%command in the {\bfseries preamble} (before the command
%``\verb|\begin{document}|'') of your \LaTeX\ source:
%\begin{verbatim}
%  \citestyle{acmauthoryear}
%\end{verbatim}
%
%
%  Some examples.  A paginated journal article \cite{Abril07}, an
%  enumerated journal article \cite{Cohen07}, a reference to an entire
%  issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a
%  monograph/whole book in a series (see 2a in spec. document)
%  \cite{Harel79}, a divisible-book such as an anthology or compilation
%  \cite{Editor00} followed by the same example, however we only output
%  the series if the volume number is given \cite{Editor00a} (so
%  Editor00a's series should NOT be present since it has no vol. no.),
%  a chapter in a divisible book \cite{Spector90}, a chapter in a
%  divisible book in a series \cite{Douglass98}, a multi-volume work as
%  book \cite{Knuth97}, a couple of articles in a proceedings (of a
%  conference, symposium, workshop for example) (paginated proceedings
%  article) \cite{Andler79, Hagerup1993}, a proceedings article with
%  all possible elements \cite{Smith10}, an example of an enumerated
%  proceedings article \cite{VanGundy07}, an informally published work
%  \cite{Harel78}, a couple of preprints \cite{Bornmann2019,
%    AnzarootPBM14}, a doctoral dissertation \cite{Clarkson85}, a
%  master's thesis: \cite{anisi03}, an online document / world wide web
%  resource \cite{Thornburg01, Ablamowicz07, Poker06}, a video game
%  (Case 1) \cite{Obama08} and (Case 2) \cite{Novak03} and \cite{Lee05}
%  and (Case 3) a patent \cite{JoeScientist001}, work accepted for
%  publication \cite{rous08}, 'YYYYb'-test for prolific author
%  \cite{SaeediMEJ10} and \cite{SaeediJETC10}. Other cites might
%  contain 'duplicate' DOI and URLs (some SIAM articles)
%  \cite{Kirschmer:2010:AEI:1958016.1958018}. Boris / Barbara Beeton:
%  multi-volume works as books \cite{MR781536} and \cite{MR781537}. A
%  couple of citations with DOIs:
%  \cite{2004:ITE:1009386.1010128,Kirschmer:2010:AEI:1958016.1958018}. Online
%  citations: \cite{TUGInstmem, Thornburg01, CTANacmart}.
%  Artifacts: \cite{R} and \cite{UMassCitations}.
%
%\section{Acknowledgments}
%
%Identification of funding sources and other support, and thanks to
%individuals and groups that assisted in the research and the
%preparation of the work should be included in an acknowledgment
%section, which is placed just before the reference section in your
%document.
%
%This section has a special environment:
%\begin{verbatim}
%  \begin{acks}
%  ...
%  \end{acks}
%\end{verbatim}
%so that the information contained therein can be more easily collected
%during the article metadata extraction phase, and to ensure
%consistency in the spelling of the section heading.
%
%Authors should not prepare this section as a numbered or unnumbered {\verb|\section|}; please use the ``{\verb|acks|}'' environment.
%
%\section{Appendices}
%
%If your work needs an appendix, add it before the
%``\verb|\end{document}|'' command at the conclusion of your source
%document.
%
%Start the appendix with the ``\verb|appendix|'' command:
%\begin{verbatim}
%  \appendix
%\end{verbatim}
%and note that in the appendix, sections are lettered, not
%numbered. This document has two appendices, demonstrating the section
%and subsection identification method.
%
%\section{Multi-language papers}
%
%Papers may be written in languages other than English or include
%titles, subtitles, keywords and abstracts in different languages (as a
%rule, a paper in a language other than English should include an
%English title and an English abstract).  Use \verb|language=...| for
%every language used in the paper.  The last language indicated is the
%main language of the paper.  For example, a French paper with
%additional titles and abstracts in English and German may start with
%the following command
%\begin{verbatim}
%\documentclass[sigconf, language=english, language=german,
%               language=french]{acmart}
%\end{verbatim}
%
%The title, subtitle, keywords and abstract will be typeset in the main
%language of the paper.  The commands \verb|\translatedXXX|, \verb|XXX|
%begin title, subtitle and keywords, can be used to set these elements
%in the other languages.  The environment \verb|translatedabstract| is
%used to set the translation of the abstract.  These commands and
%environment have a mandatory first argument: the language of the
%second argument.  See \verb|sample-sigconf-i13n.tex| file for examples
%of their usage.
%
%\section{SIGCHI Extended Abstracts}
%
%The ``\verb|sigchi-a|'' template style (available only in \LaTeX\ and
%not in Word) produces a landscape-orientation formatted article, with
%a wide left margin. Three environments are available for use with the
%``\verb|sigchi-a|'' template style, and produce formatted output in
%the margin:
%\begin{description}
%\item[\texttt{sidebar}:]  Place formatted text in the margin.
%\item[\texttt{marginfigure}:] Place a figure in the margin.
%\item[\texttt{margintable}:] Place a table in the margin.
%\end{description}
%
%%%
%%% The acknowledgments section is defined using the "acks" environment
%%% (and NOT an unnumbered section). This ensures the proper
%%% identification of the section in the article metadata, and the
%%% consistent spelling of the heading.
%\begin{acks}
%To Robert, for the bagels and explaining CMYK and color spaces.
%\end{acks}
%
%%%
%%% The next two lines define the bibliography style to be used, and
%%% the bibliography file.

\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}

%
%%%
%%% If your work has an appendix, this is the place to put it.
%\appendix
%
%\section{Research Methods}
%
%\subsection{Part One}
%
%Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
%malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
%sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
%vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
%lacinia dolor. Integer ultricies commodo sem nec semper.
%
%\subsection{Part Two}
%
%Etiam commodo feugiat nisl pulvinar pellentesque. Etiam auctor sodales
%ligula, non varius nibh pulvinar semper. Suspendisse nec lectus non
%ipsum convallis congue hendrerit vitae sapien. Donec at laoreet
%eros. Vivamus non purus placerat, scelerisque diam eu, cursus
%ante. Etiam aliquam tortor auctor efficitur mattis.
%
%\section{Online Resources}
%
%Nam id fermentum dui. Suspendisse sagittis tortor a nulla mollis, in
%pulvinar ex pretium. Sed interdum orci quis metus euismod, et sagittis
%enim maximus. Vestibulum gravida massa ut felis suscipit
%congue. Quisque mattis elit a risus ultrices commodo venenatis eget
%dui. Etiam sagittis eleifend elementum.
%
%Nam interdum magna at lectus dignissim, ac dignissim lorem
%rhoncus. Maecenas eu arcu ac neque placerat aliquam. Nunc pulvinar
%massa et mattis lacinia.

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.

